"""
ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ ì „ë ¥ ì˜ˆì¸¡ - ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰
============================================

ì‹¤ì œ ë°ì´í„°ì— ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì ìš©í•˜ëŠ” ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
"""

import pandas as pd
import numpy as np
import os
import sys
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from src.Preprocessing.data_preprocessing import PowerDataPreprocessor, QuickPreprocessor

def load_data_sample(file_path: str, sample_size: int = 100000) -> pd.DataFrame:
    """
    ëŒ€ìš©ëŸ‰ ë°ì´í„°ì˜ ìƒ˜í”Œì„ ë¡œë“œ
    
    Args:
        file_path: ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        sample_size: ìƒ˜í”Œ í¬ê¸°
        
    Returns:
        ìƒ˜í”Œ ë°ì´í„°í”„ë ˆì„
    """
    print(f"ğŸ“Š ë°ì´í„° ìƒ˜í”Œ ë¡œë”© ì¤‘... (ìƒ˜í”Œ í¬ê¸°: {sample_size:,})")
    
    # íŒŒì¼ í¬ê¸° í™•ì¸
    file_size = os.path.getsize(file_path) / (1024**3)  # GB
    print(f"ğŸ“ íŒŒì¼ í¬ê¸°: {file_size:.2f} GB")
    
    # ìƒ˜í”Œ ë¡œë”©
    if file_size > 1.0:  # 1GB ì´ìƒì¸ ê²½ìš° ìƒ˜í”Œë§
        # ì „ì²´ í–‰ ìˆ˜ ì¶”ì •
        with open(file_path, 'r') as f:
            first_line = f.readline()
            
        # ê±´ë„ˆë›¸ í–‰ ê³„ì‚°
        total_lines = sample_size * 10  # ëŒ€ëµì  ì¶”ì •
        skip_rows = np.random.choice(range(1, total_lines), 
                                   size=total_lines-sample_size-1, 
                                   replace=False)
        
        data = pd.read_csv(file_path, skiprows=skip_rows, nrows=sample_size)
    else:
        data = pd.read_csv(file_path)
        if len(data) > sample_size:
            data = data.sample(n=sample_size).sort_index()
    
    print(f"ë°ì´í„° ë¡œë”© ì™„ë£Œ: {data.shape}")
    return data

def run_quick_preprocessing():
    """ë¹ ë¥¸ ì „ì²˜ë¦¬ ì‹¤í–‰"""
    print("\n" + "="*80)
    print("âš¡ ë¹ ë¥¸ ì „ì²˜ë¦¬ ì‹¤í–‰")
    print("="*80)
    
    # ë°ì´í„° ë¡œë“œ
    data_path = project_root / "data" / "raw" / "train.csv"
    
    try:
        # ì‘ì€ ìƒ˜í”Œë¡œ ì‹œì‘
        data = load_data_sample(str(data_path), sample_size=5000)
        
        print(f"\në°ì´í„° ê¸°ë³¸ ì •ë³´:")
        print(f"   - í¬ê¸°: {data.shape}")
        print(f"   - ì»¬ëŸ¼: {len(data.columns)}ê°œ")
        print(f"   - ë©”ëª¨ë¦¬: {data.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        # ì»¬ëŸ¼ ì •ë³´ ì¶œë ¥
        print(f"\nì»¬ëŸ¼ ì •ë³´:")
        print(f"   - ì‹œê°„ ì»¬ëŸ¼: {[col for col in data.columns if 'time' in col.lower() or 'date' in col.lower()]}")
        print(f"   - ìˆ«ìí˜• ì»¬ëŸ¼: {len(data.select_dtypes(include=[np.number]).columns)}ê°œ")
        
        # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
        print(f"\nìƒ˜í”Œ ë°ì´í„°:")
        print(data.head())
        
        # ë¹ ë¥¸ ì „ì²˜ë¦¬ ì ìš©
        cleaned_data = QuickPreprocessor.quick_clean(data.copy())
        
        # ê¸°ë³¸ ì‹œê°„ íŠ¹ì„± ì¶”ê°€ (ì‹œê°„ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
        time_cols = [col for col in cleaned_data.columns 
                    if any(keyword in col.lower() for keyword in ['time', 'date'])]
        
        if time_cols:
            time_col = time_cols[0]
            print(f"\nì‹œê°„ íŠ¹ì„± ì¶”ê°€ (ì»¬ëŸ¼: {time_col})")
            cleaned_data = QuickPreprocessor.add_basic_time_features(cleaned_data, time_col)
        
        # ê²°ê³¼ ì €ì¥
        output_path = project_root / "data" / "processed" / f"quick_processed_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        cleaned_data.to_csv(output_path, index=False)
        
        print(f"\në¹ ë¥¸ ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"   - ì›ë³¸ í¬ê¸°: {data.shape}")
        print(f"   - ì²˜ë¦¬ í›„ í¬ê¸°: {cleaned_data.shape}")
        print(f"   - ì €ì¥ ìœ„ì¹˜: {output_path}")
        
        return cleaned_data
        
    except Exception as e:
        print(f"ë¹ ë¥¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

def run_full_preprocessing():
    """ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print("\n" + "="*80)
    print("ğŸ”§ ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
    print("="*80)
    
    # ì „ì²˜ë¦¬ ì„¤ì •
    config = {
        'missing_value': {
            'method': 'interpolate',  # ë¹ ë¥¸ ì„ í˜• ë³´ê°„
            'interpolation_method': 'linear'
        },
        'outlier_detection': {
            'method': 'iqr',
            'threshold': 1.5,
            'action': 'cap'
        },
        'noise_filtering': {
            'method': 'moving_average',
            'window_size': 3
        },
        'scaling': {
            'method': 'robust'  # ì´ìƒì¹˜ì— ê°•ê±´í•œ ìŠ¤ì¼€ì¼ë§
        },
        'feature_engineering': {
            'time_features': True,
            'lag_features': False,  # ì²˜ìŒì—ëŠ” ë„ê³  ì‹œì‘
            'rolling_features': False,
            'lag_periods': [1, 6, 24],
            'rolling_windows': [6, 24]
        }
    }
    
    # ì „ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    preprocessor = PowerDataPreprocessor(config)
    
    try:
        # ë°ì´í„° ë¡œë“œ (10ë§Œê°œ ìƒ˜í”Œ)
        data_path = project_root / "data" / "raw" / "train.csv"
        data = load_data_sample(str(data_path), sample_size=100000)
        
        print(f"\nì „ì²˜ë¦¬ ì „ ë°ì´í„° ì •ë³´:")
        print(f"   - í¬ê¸°: {data.shape}")
        print(f"   - ê²°ì¸¡ì¹˜: {data.isnull().sum().sum()}ê°œ")
        print(f"   - ë©”ëª¨ë¦¬: {data.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
        
        # ì „ì²˜ë¦¬ ì‹¤í–‰
        processed_data = preprocessor.preprocess_data(data)
        
        # ê²°ê³¼ ì‹œê°í™”
        sample_cols = processed_data.select_dtypes(include=[np.number]).columns[:3]
        if len(sample_cols) > 0:
            preprocessor.visualize_preprocessing_results(
                data, processed_data, list(sample_cols)
            )
        
        # ê²°ê³¼ ì €ì¥
        output_path = preprocessor.save_preprocessed_data(processed_data)
        
        print(f"\nì „ì²´ ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"   - ì›ë³¸ í¬ê¸°: {data.shape}")
        print(f"   - ì²˜ë¦¬ í›„ í¬ê¸°: {processed_data.shape}")
        print(f"   - ìƒˆ í”¼ì²˜: {len(preprocessor.feature_names)}ê°œ")
        print(f"   - ì €ì¥ ìœ„ì¹˜: {output_path}")
        
        return processed_data
        
    except Exception as e:
        print(f"ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None

def analyze_data_structure():
    """ë°ì´í„° êµ¬ì¡° ë¶„ì„"""
    print("\n" + "="*80)
    print("ğŸ” ë°ì´í„° êµ¬ì¡° ë¶„ì„")
    print("="*80)
    
    data_path = project_root / "data" / "raw" / "train.csv"
    
    try:
        # í—¤ë”ë§Œ ì½ê¸°
        header_data = pd.read_csv(data_path, nrows=5)
        
        print(f"ê¸°ë³¸ ì •ë³´:")
        print(f"   - ì»¬ëŸ¼ ìˆ˜: {len(header_data.columns)}")
        print(f"   - íŒŒì¼ í¬ê¸°: {os.path.getsize(data_path) / (1024**3):.2f} GB")
        
        print(f"\nì»¬ëŸ¼ ëª©ë¡ (ì²˜ìŒ 20ê°œ):")
        for i, col in enumerate(header_data.columns[:20]):
            dtype = header_data[col].dtype
            print(f"   {i+1:2d}. {col}: {dtype}")
        
        if len(header_data.columns) > 20:
            print(f"   ... ì´ {len(header_data.columns)}ê°œ ì»¬ëŸ¼")
        
        print(f"\nìƒ˜í”Œ ë°ì´í„°:")
        print(header_data.head())
        
        # ë°ì´í„° íƒ€ì… ë¶„ì„
        numeric_cols = header_data.select_dtypes(include=[np.number]).columns
        text_cols = header_data.select_dtypes(include=['object']).columns
        
        print(f"\në°ì´í„° íƒ€ì… ë¶„í¬:")
        print(f"   - ìˆ«ìí˜•: {len(numeric_cols)}ê°œ")
        print(f"   - í…ìŠ¤íŠ¸í˜•: {len(text_cols)}ê°œ")
        
        if len(text_cols) > 0:
            print(f"   - í…ìŠ¤íŠ¸ ì»¬ëŸ¼: {list(text_cols)}")
        
        return header_data
        
    except Exception as e:
        print(f"ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬ ì „ë ¥ ì˜ˆì¸¡ - ë°ì´í„° ì „ì²˜ë¦¬")
    print("="*80)
    
    # 1. ë°ì´í„° êµ¬ì¡° ë¶„ì„
    data_info = analyze_data_structure()
    
    if data_info is None:
        return
    
    # 2. ì‚¬ìš©ì ì„ íƒ
    print(f"\nì „ì²˜ë¦¬ ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
    print(f"   1. ë¹ ë¥¸ ì „ì²˜ë¦¬ (ê¸°ë³¸ ì •ë¦¬ë§Œ, ë¹ ë¦„)")
    print(f"   2. ì „ì²´ ì „ì²˜ë¦¬ (ì™„ì „í•œ íŒŒì´í”„ë¼ì¸, ì‹œê°„ ì†Œìš”)")
    print(f"   3. ë‘˜ ë‹¤ ì‹¤í–‰")
    
    choice = input("\nì„ íƒ (1-3): ").strip()
    
    if choice == "1":
        result = run_quick_preprocessing()
    elif choice == "2":
        result = run_full_preprocessing()
    elif choice == "3":
        print("\në¹ ë¥¸ ì „ì²˜ë¦¬ë¶€í„° ì‹œì‘...")
        quick_result = run_quick_preprocessing()
        
        if quick_result is not None:
            print("\nì „ì²´ ì „ì²˜ë¦¬ ì‹¤í–‰...")
            full_result = run_full_preprocessing()
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë¹ ë¥¸ ì „ì²˜ë¦¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        result = run_quick_preprocessing()
    
    print(f"\nì „ì²˜ë¦¬ ì‘ì—… ì™„ë£Œ!")
    print(f"ê²°ê³¼ëŠ” 'data/processed/' ë””ë ‰í† ë¦¬ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main() 